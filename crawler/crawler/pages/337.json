{'html': '<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">\r<html>\r<head>\r<title>e s c a p e</title>\r<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">\r<meta name="description" content="esc-design, interaction design for dynamic interactive environments, 7c Sunderland Terrace, London W2 5PA, UK">\r<script language="JavaScript" type="text/JavaScript">\r<!--\r\rfunction MM_reloadPage(init) {  //reloads the window if Nav4 resized\r  if (init==true) with (navigator) {if ((appName=="Netscape")&&(parseInt(appVersion)==4)) {\r    document.MM_pgW=innerWidth; document.MM_pgH=innerHeight; onresize=MM_reloadPage; }}\r  else if (innerWidth!=document.MM_pgW || innerHeight!=document.MM_pgH) location.reload();\r}\rMM_reloadPage(true);\r//-->\r</script>\r<link href="text_research.css" rel="stylesheet" type="text/css">\r</head>\r<body bgcolor="#999999" text="#FFFFFF">\r<div id="Layer3" style="position:absolute; left:95px; top:270px; width:175px; height:200px; z-index:3"> \r  <table width="100%" border="0" cellspacing="0" cellpadding="0">\r    <tr> \r      <td><h1 align="right">Kaleidoscope</h1>\r        <p align="right"><a href="kaleidoscopedesign_p1.html">Overview</a></p>\r        <p align="right"><a href="kaleidoscope.html">Idea </a></p>\r        <p align="right"><a href="kaleidoscope_programming.html">Programming ideas</a></p>\r        <p align="right"><a href="lacing.html">Lacing</a></p></td>\r    </tr>\r  </table>\r  <h1>&nbsp;</h1>\r  <p>&nbsp;</p>\r</div>\r<div id="Layer1" style="position:absolute; left:0px; top:188px; width:1300px; height:44px; z-index:1"><img src="research/images/titlebar.gif" width="1300" height="44" border="0" usemap="#Map"> \r  <map name="Map">\r    <area shape="rect" coords="781,17,874,35" href="presencia.html">\r    <area shape="rect" coords="659,15,752,35" href="crossings.html">\r    <area shape="rect" coords="509,15,632,36" href="kaleidoscope.html">\r    <area shape="rect" coords="373,18,471,36" href="earthdiver.html">\r    <area shape="rect" coords="30,1,272,38" href="../index.html">\r  </map>\r</div>\r<div id="Layer2" style="position:absolute; left:430px; top:270; width:450; height:850; z-index:2"> \r  <h1>Kaleidoscope</h1>\r  <h3><img src="research/images/kaleidoscope2.jpg" width="450" height="258"></h3>\r  <h2>Aim</h2>\r  <p>Kaleidoscope investigates dynamic models of interaction. Taking point of \r    departure in the conceptualisation of the interface as a site for learning, \r    Kaleidoscope aims to create an intelligent interface where the parameters \r    of interaction are set in an evolving relationship to the parameters of the \r    digital environment.</p>\r  <p>In the Periscope, I see what you hear and Spawn the interface is seen as \r    an environment for action, a medium through which new actions are learnt and \r    incorporated. Kaleidoscope probes the thinking of the interface as an evolving \r    environment for learning. What happens when the interface learns from the \r    actions of the user? What are the parameters of affect as user adapts to the \r    system and system adapts to the user?</p>\r  <h2>Objective: </h2>\r  <ul>\r    <li>To investigate and propose means of defining a dynamic mapping between \r      the parameters of input (interaction) and output (digital environment)</li>\r    <li> To investigate and propose means of understanding mutual learning processes \r      existing between (a learning) user and (an intelligent) environment. </li>\r    <li>To develop an intuitive interface for the interaction with a dynamic interactive \r      environment. </li>\r  </ul>\r  <h3>&nbsp;</h3>\r  <h2>Key terms</h2>\r  <p>Evolving ecologies, complex systems, iterative systems, non-linear dynamic \r    systems, phase space</p>\r  <h2>Research questions</h2>\r  <p>The core theme in Kaleidoscope is the establishing of a dynamic relationship \r    between user and environment, an evolving system where both intelligences \r    learn to respond to one another. </p>\r  <p>Kaleidoscope is primarily concerned with the making of an intelligent interface \r    where the mapping between the parameters of interaction are set in a changing \r    relationship to the parameters of digital environment. This dynamic mapping \r    allows a flow between the interactions of the user and the reactions of the \r    digital environment.</p>\r  <p> In the project I see what you hear (CAVE experiment) it was experienced \r    that users would invent new actions which exceeded or extended the designed \r    interactions of the system. Users would learn to create short or sharp sounds \r    so as to clear the space (drawing new splines outside the display environment \r    of the CAVE) and allow for a fresh start. As well as learning to control the \r    parameters of pitch, volume and movement interaction, user found inventive \r    ways of manipulating the system so as to interact in a manner which was meaningful \r    to them. These new, or unpredicted actions, were understood as action on par \r    with the intended interactions of the system.</p>\r  <p>Kaleidoscope seeks explore the formation of new interactions. By releasing \r    the digital from a pre-conceived model of intuitive interaction (mapping) \r    the aim is to explore if and how the user can create an understanding of her \r    affect on the system.</p>\r  <h2> Programming: </h2>\r  <p> The <a href="kaleidoscope_programming.html">programme seeks to guess repeated \r    gestures</a> (interactions with the physical interface) and map simple these \r    to digital events. <br>\r    This could be done through the building of a table (array) that caches the \r    gestures and categorises them. As the user repeats actions the &#8216;solidity&#8217; \r    of the gesture is enforced.<br>\r    <br>\r    <strong><em>Question:</em></strong><br>\r    Could we use reinforcement learning as a paradigm? </p>\r  <h2><br>\r    Interface </h2>\r  <p>The prototype is conceived as a very simple physical interface to be manipulated \r    by the hand only. Conceived as a movable screen the interface merges interaction \r    and display into one thereby creating a strong link between doing and seeing. \r    The screen is tracked by a camera (employing code from Spawn) which sees the \r    screen being moved around a central pivot. The different ways of manipulating \r    the screen (slow, fast, jerky, smooth (changes to the set parameters of velocity, \r    time, position)) allows the user to interact in different ways. Learning from \r    the Periscope installation it is expected that users will engage with the \r    interface in very different ways despite it having only a single parameter \r    for movement around the central pivot. <br>\r    <br>\r    <em><strong> Parameters of interaction: </strong></em><br>\r    Tilt over time creates the parameters of <em><strong>smoothness </strong></em>(jerky/smooth), \r    <em> <strong>speed </strong></em>(slow/still/fast), <em><strong>degree </strong></em>(small/large \r    movement) and <em><strong>position </strong></em>(where within the totality \r    of the pan the interaction takes place).</p>\r  <h2>Visualisation </h2>\r  <p>The idea for the visualisation is a set of virtual objects affected by the \r    way the interaction is are done (learning from Giver of Names). As the user \r    manipulates the screen around the central pivot point the virtual objects \r    tumble and fall as is affected by a mutual (mixed) sense of gravity. The aim \r    for the visualisation is it should be dynamic but simple enough to allow us \r    to understand the learning of the interface. A second aim is to create correlations \r    between the physical and the digital environment through the perceived dynamics \r    of the environment (e.g. through the force of gravity). This is a simple Mixed \r    Reality construct.In the first stage this sense of gravity determines the \r    behaviour the entirety of the system. </p>\r  <p><img src="research/images/ballsonly_animation.gif" width="450" height="242"></p>\r  <p>This gives the output parameters of: Self movement creates the parameters \r    of <em><strong>fall down </strong></em>(slide/roll), <em><strong>bounce </strong></em>(high/low), \r    <em> <strong>friction </strong></em>(high/low), <em><strong>speed </strong></em>(slow/still/fast).</p>\r  <p> Further parameters could be: Growth (big/small object), transparency, trace, \r    colour.</p>\r  <h2>Second stage of visualisation</h2>\r  <p><img src="research/images/STRINGS_animation.gif" width="450" height="242"></p>\r  <p>In the second stage the objects might form connections (springs) to each \r    other (here learning from the Biotica project by Richard Brown, as well as \r    Carl Simms and the motions of the double pendulum). These might be rule based \r    allowing for connections to form and dissapate across the time of the experiment. \r    Learning from Biotica&#8217;s bions new dynamic variable could be: Charge, \r    Mass, Velocity, Size, Neural value (?), Colour, Reproduction, Death, Form \r    spring, Form neural connection, Form skin.</p>\r  <h2>Display</h2>\r  <p>I would like to test whether we can use passive stereo as a display. This \r    would work well for seeing the bounce of the digital objects. </p>\r  <h2>Further questions</h2>\r  <p>The idea of thinking the system as the entirety of the experience including \r    both the digital environment and the user as well as interface it self. </p>\r  <ul>\r    <li> What is site (interface)</li>\r    <li> What is space (phase space of possible interactions)</li>\r    <li> What is presence (singularity of the actualised) </li>\r  </ul>\r  <p>Both input and output parameters are dynamic properties of the system rather \r    than formal qualities of the environment. <br>\r    <br>\r    Sand box - top down projection (or bottom up) &#8211; the problem here is \r    that the projection will be stable (good for stereo) which means that the \r    interactions have to affect the setting of the virtual camera (this is interesting \r    in it self &#8211; but the delay might be a bit weird).</p>\r  <h2>References: </h2>\r  <ul>\r    <li>Simon Penny: auto-didactic interface in Traces</li>\r    <li> Carl Simms:</li>\r    <li> Richard Brown: concept of strings in Biotica as well as the idea of the \r      user as agent on par with the digital agents of the system only with different \r    </li>\r    <li>Jeffrey Shaw: the combined interface and display environment in The Golden \r      Calf as well as the Mixed Reality strategy of spatial correlation between \r      the physical and digital. </li>\r    <li>David Rokeby: Giver of Names</li>\r    <li> Presencia: similar programme of thinking</li>\r    <li> Alexa deFerranti: Kaleidoscope</li>\r  </ul>\r  <p>&nbsp;</p>\r  <p>&nbsp;</p>\r  <p>&nbsp;</p>\r  <p>&nbsp;</p>\r  <p>&nbsp;</p>\r</div>\r</body>\r</html>\r',
 'pid': 337,
 'url': 'http://www0.cs.ucl.ac.uk/research/vr/Projects/VLF/Media/escape/kaleidoscope.html'}