{'html': b'<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">\n'
         b'<!-- saved from url=(0051)http://web4.cs.ucl.ac.uk/staff/i.yu/public'
         b'ations/ -->\n<HTML><HEAD><META http-equiv="Content-Type" content='
         b'"text/html; charset=ISO-8859-1">\n   \n   <META name="GENERATOR" c'
         b'ontent="Mozilla/4.7 [en] (X11; U; IRIX 6.5 IP32) [Netscape]">\n  '
         b' <TITLE>Publications</TITLE>\n   <LINK href="./general.css" rel="'
         b'stylesheet" type="text/css">\n   <LINK href="./publications.css" '
         b'rel="stylesheet" type="text/css">\n   <LINK rel="icon" href="http'
         b'://web4.cs.ucl.ac.uk/staff/i.yu/pics/JK.ico">\n   <LINK rel="SHOR'
         b'TCUT ICON" href="http://web4.cs.ucl.ac.uk/staff/i.yu/pics/JK.ico'
         b'">\n<SCRIPT src="./urchin.js" type="text/javascript"></SCRIPT><SC'
         b'RIPT src="./prototype.js" type="text/javascript"></SCRIPT><SCRIPT sr'
         b'c="./scriptaculous.js" type="text/javascript"></SCRIPT><SCRIPT type='
         b'"text/javascript" src="./builder.js"></SCRIPT><SCRIPT type="text/jav'
         b'ascript" src="./effects.js"></SCRIPT><SCRIPT type="text/javascript" '
         b'src="./dragdrop.js"></SCRIPT><SCRIPT type="text/javascript" src="./c'
         b'ontrols.js"></SCRIPT><SCRIPT type="text/javascript" src="./slider.js'
         b'"></SCRIPT><SCRIPT type="text/javascript" src="./sound.js"></SCRIPT>'
         b'</HEAD><BODY>\n\n<SCRIPT type="text/javascript">\n<!--\n// from Jona'
         b'than Snook: www.snook.ca\nfunction getElementsByClassName(node, c'
         b"lassname)\n{\n    var a = [];\n    var re = new RegExp('\\\\b' + "
         b"classname + '\\\\b');\n    var els = node.getElementsByTagName("
         b'"*");\n    for(var i=0,j=els.length; i<j; i++)\n        if(re.test'
         b'(els[i].className))a.push(els[i]);\n    return a;\n}\n\nvar toggle ='
         b' 0;\nfunction toggleStyle() \n{\n  toggle = 1 - toggle;\n//  documen'
         b"t.all['image'].style.display = toggle ? 'none' : 'block';\n// doc"
         b"ument.all['abstract'].style.display = toggle ? 'none' : 'block';"
         b'\n\n  // get rid of abstracts\n  abstracts = getElementsByClassName'
         b"(document,'abstract');\n  for(var i = 0; i < abstracts.length; i+"
         b"+) {\n   // abstracts[i].style.display = toggle ? 'none' : 'block"
         b"';\n   abstracts[i].style.display = 'block';\n   if( !toggle ) Eff"
         b'ect.BlindDown(abstracts[i]);\n   else Effect.BlindUp(abstracts[i]'
         b');\n  }\n\n  // get rid of images\n  images = getElementsByClassName'
         b"(document,'image');\n  for(var i = 0; i < images.length; i++) {\n "
         b"  //-> HIDE\n   //images[i].style.display = toggle ? 'none' : 'bl"
         b"ock';\n   //-> FANCY: scale them...\n   //var image = images[i].ge"
         b"tElementsByTagName( 'img' );\n   //image[0].style.width = toggle "
         b"? '80px' : '190px';\n   //image[0].style.height = 'auto';\n  }\n}\n/"
         b'/-->\n</SCRIPT>\n\n               \n<DIV id="main">\n<DIV id="hea'
         b'der">\n <DIV id="headerentry">publi</DIV><DIV id="headerentry2">c'
         b'ations</DIV>\n</DIV>\n<DIV id="navigator">\n<UL>\n<LI><A class="home'
         b'" href="http://web4.cs.ucl.ac.uk/staff/i.yu/"><SPAN>home</SPAN></A><'
         b'/LI>\n<LI><A class="publications" href="http://web4.cs.ucl.ac.uk/'
         b'staff/i.yu/publications"><SPAN>publications</SPAN></A></LI>\n<LI>'
         b'<A class="teaching" href="http://web4.cs.ucl.ac.uk/staff/i.yu/teachi'
         b'ng/"><SPAN>teaching</SPAN></A></LI>\n<LI><A class="links" href="h'
         b'ttp://web4.cs.ucl.ac.uk/staff/i.yu/links/"><SPAN>links</SPAN></A></L'
         b'I>\n<LI><A class="contact" href="http://web4.cs.ucl.ac.uk/staff/i'
         b'.yu/contact/"><SPAN>about</SPAN></A></LI>\n</UL>\n</DIV>\n     '
         b' \n\n<DIV id="content">\n<DIV class="section">Publications\n<FONT si'
         b'ze="-2"><A href="javascript:toggleStyle();">toggle abstracts</A></FO'
         b'NT> </DIV>\n<DIV class="year"></DIV>\n\n\n<DIV class="entry">\n  '
         b'<DIV class="image" name="image"> <IMG src="../pics/image01.jpg" alt='
         b'"image">   </DIV>\n  <DIV class="title">  Visual Realism Enhances'
         b' Realistic Response in An Immersive Virtual Environment - Part2 (Fea'
         b'ture Article)</DIV>\n  <DIV class="author">  I. Yu, J. Mortensen,'
         b' P. Khanna,B. Spanlang and M. Slater   </DIV>\n  <DIV class="jour'
         b'nal">   <IMG src="../icons/journal.png"> IEEE Computer Graphics and '
         b'Applications - ISI Impact Factor: 1.8 </DIV>\n  <DIV class="datep'
         b'ages">   ISSN:0272-1716,  32(7), Nov.-Dec. 2012, pages 36-45</DI'
         b'V>\n    <DIV class="download">  \n  \t<A href="http://ieeexplore.ie'
         b'ee.org/xpl/articleDetails.jsp?tp=&arnumber=6353430"><IMG src="../ico'
         b'ns/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.y'
         b'u/pub/Yu_IEEE_12.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A hr'
         b'ef="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_12_Bib.htm"><IMG'
         b' src="../icons/bibtex32.png"></A>     \n    </DIV> \n  <!-- <DIV c'
         b'lass="abstract" name="abstract">  Does realistic lighting in an imme'
         b'rsive virtual reality application enhance presence, where participan'
         b'ts feel that they are in the scene and behave correspondingly? Our p'
         b'revious study indicated that presence is more likely with real-time '
         b'ray tracing compared with ray casting, but we could not separate the'
         b' effects of overall quality of illumination from the dynamic effects'
         b' of real-time shadows and reflections. Here we describe an experimen'
         b't where 20 people experienced a scene rendered with global or local '
         b'illumination. However, in both conditions there were dynamically cha'
         b'nging shadows and reflections. We found that the quality of illumina'
         b'tion did not impact presence, so that the earlier result must have b'
         b'een due to dynamic shadows and reflections. However, global illumina'
         b'tion resulted in greater plausibility - participants were more likel'
         b'y to respond as if the virtual events were real. We conclude that gl'
         b'obal illumination does impact the responses of participants and is w'
         b'orth the effort.</DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <'
         b'DIV class="image" name="image"><IMG src="../pics/image02.jpg" alt="i'
         b'mage"></DIV>\n  <DIV class="title"> Display-aware Image Editing <'
         b'/DIV>\n  <DIV class="author"> Won-Ki Jeong, Micah K. Johnson, Ins'
         b'u Yu, Jan Kautz, Hanspeter Pfister, and Sylvain Paris </DIV>\n  <'
         b'DIV class="proceedings"> IEEE International Conference on Computiona'
         b'l Photography (ICCP) </DIV>\n  <DIV class="datepages">  April 201'
         b'1, pages 1-8 </DIV>\n  <DIV class="download"> \n  <A href="http://'
         b'ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5753125"><IMG src="../'
         b'icons/ieee32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff'
         b'/i.yu/pub/Yu_ICCP_11.pdf"><IMG src="../icons/pdf32.png"></A> \n  '
         b'<A href="http://web4.cs.ucl.ac.uk/staff/j.kautz/videos/Display-aware'
         b'_Image_Editing.mov"><IMG src="../icons/movie32.png"></A>\t     \n '
         b'   </DIV>     \n  <!--<DIV class="abstract" name="abstract"> We d'
         b'escribe a set of image editing and viewing tools that explicitly tak'
         b'e into account the resolution of the display on which the image is v'
         b'iewed. Our approach is twofold. First, we design editing tools that '
         b'process only the visible data, which is useful for images larger tha'
         b'n the display. This encompasses cases such as multi-image panoramas '
         b'and high-resolution medical data. Second, we propose an adaptive way'
         b' to set viewing parameters such brightness and contrast. Because we '
         b'deal with very large images, different locations and scales often re'
         b'quire different viewing parameters. We let users set these parameter'
         b's at a few places and interpolate satisfying values everywhere else.'
         b' We demonstrate the efficiency of our approach on different display '
         b'and image sizes. Since the computational complexity to render a view'
         b' depends on the display resolution and not the actual input image re'
         b'solution, we achieve interactive image editing even on a 16 gigapixe'
         b'l image. </DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV cla'
         b'ss="image" name="image"> <IMG src="../pics/image03.jpg" alt="image">'
         b'   </DIV>\n  <DIV class="title">  Perceptual Influence of Approxi'
         b'mate Visibility in Indirect Illumination  </DIV>\n  <DIV class="a'
         b'uthor">  I. Yu, A. Cox, M. H. Kim, T. Ritschel, T. Grosch, C. Dachsb'
         b'acher, J. Kautz  </DIV>\n  <DIV class="journal">  <IMG src="../ic'
         b'ons/journal.png"> ACM Transactions on Applied Perception (Presented '
         b'at APGV 2009) - ISI Impact Factor: 1.44</DIV>\n  <DIV class="date'
         b'pages">  ISSN:1544-3558, 6(4), September 2009, pages 24:1-24:14</DIV'
         b'>\n  <DIV class="download">  \n  \t<A href="http://doi.acm.org/10.1'
         b'145/1620993.1609971"><IMG src="../icons/acm32.png"></A>\n\t<A href'
         b'="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TAP_09.pdf"><IMG src=".'
         b'./icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staf'
         b'f/i.yu/pub/Yu_TAP_09.mov"><IMG src="../icons/movie32.png"></A>  '
         b'   \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TAP_09_'
         b'Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>\n '
         b'  <!--<DIV class="abstract" name="abstract"> In this paper we evalua'
         b'te the use of approximate visibility for efficient global illuminati'
         b'on. Traditionally, accurate visibility is used in light transport. H'
         b'owever, the indirect illumination we perceive on a daily basis is ra'
         b'rely of high frequency nature, as the most significant aspect of lig'
         b'ht transport in real-world scenes is diffuse, and thus displays a sm'
         b'ooth gradation. This raises the question of whether accurate visibil'
         b'ity is perceptually necessary in this case. To answer this question,'
         b' we conduct a psychophysical study on the perceptual influence of ap'
         b'proximate visibility on indirect illumination. This study reveals th'
         b'at accurate visibility is not required and that certain approximatio'
         b'ns may be introduced.</DIV>-->\n   </DIV>\n\n\n<DIV class="entry'
         b'">\n  <DIV class="image" name="image"> <IMG src="../pics/image04.'
         b'jpg" alt="image">   </DIV>\n  <DIV class="title">  Visual Realism'
         b' Enhances Realistic Response in An Immersive Virtual Environment (Fe'
         b'ature Article) </DIV>\n  <DIV class="author">  M. Slater, P. Khan'
         b'na, J. Mortensen, I. Yu  </DIV>\n  <DIV class="journal">   <IMG s'
         b'rc="../icons/journal.png"> IEEE Computer Graphics and Applications -'
         b' ISI Impact Factor: 1.76</DIV>\n  <DIV class="datepages">  ISSN:0'
         b'272-1716,  29(3), May 2009, pages 76-84 </DIV>\n    <DIV class="d'
         b'ownload">  \n  \t<A href="http://dx.doi.org/10.1109/MCG.2009.55"><'
         b'IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.'
         b'ac.uk/staff/i.yu/pub/Yu_IEEE_09.pdf"><IMG src="../icons/pdf32.png"><'
         b'/A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_0'
         b'9_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>'
         b' \n  <!--<DIV class="abstract" name="abstract"> Does greater visu'
         b'al realism induce greater participant presence in immersive virtual '
         b'environments (VE)? Presence refers to how realistically participants'
         b' respond to the environment as well as their subjective sense of bei'
         b'ng in the place depicted by the VE. Thirty-three people were exposed'
         b' for three minutes to a virtual environment depicting a precipice us'
         b'ing a head-tracked head-mounted display system. Seventeen of them sa'
         b'w the environment rendered with real-time recursive ray tracing (RT)'
         b' that included shadows and reflections of their virtual body, and th'
         b'e remainder experienced the same environment rendered with ray casti'
         b'ng (RC), which did not include shadows and reflections. Participants'
         b' completed a presence questionnaire immediately after their experien'
         b'ce, and physiological responses (skin conductance and electrocardiog'
         b'ram) were recorded throughout. Results show that subjective presence'
         b' was higher for the RT environment than for the RC one and that high'
         b'er stress was induced in the RT environment compared to the RC one.<'
         b'/DIV> -->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image'
         b'" name="image"> <IMG src="../pics/image05.jpg" alt="image">   </DIV>'
         b'\n  <DIV class="title">  Real-Time Global Illumination for VR App'
         b'lications </DIV>\n  <DIV class="author">  J. Mortensen, I. Yu, P.'
         b' Khanna, M. Slater, F. Tecchia, B. Spanlang, G. Marino, M. Slater </'
         b'DIV> \n  <DIV class="journal">  <IMG src="../icons/journal.png"> '
         b'IEEE Computer Graphics and Applications - ISI Impact Factor: 1.87 </'
         b'DIV>\n  <DIV class="datepages"> ISSN:0272-1716,  28(6), November '
         b'2008, pages 56-64 </DIV>\n  <DIV class="download">  \n  \t<A href="'
         b'http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4670101"><IMG s'
         b'rc="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk'
         b'/staff/i.yu/pub/Yu_IEEE_08.pdf"><IMG src="../icons/pdf32.png"></'
         b'A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_08'
         b'_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV> '
         b'\n  <!-- <DIV class="abstract" name="abstract"> Real-time global '
         b'illumination in VR systems enhances scene realism by incorporating s'
         b'oft shadows, reflections of objects in the scene, and color bleeding'
         b'. The Virtual Light Field (VLF) method enables real-time global illu'
         b'mination rendering in VR. The VLF has been integrated with the Extre'
         b'me VR system for real-time GPU-based rendering in a Cave Automatic V'
         b'irtual Environment.</DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n'
         b'  <DIV class="image" name="image"><IMG src="../pics/image06.jpg" alt'
         b'="image"></DIV>\n  <DIV class="title"> Real-time Global Illuminat'
         b'ion in the CAVE </DIV>\n  <DIV class="author"> J. Mortensen, P. K'
         b'hanna, I. Yu, M. Slater </DIV>\n  <DIV class="proceedings"> VRST '
         b"'07: Proceedings of the 2007 ACM symposium on Virtual reality softwa"
         b're and technology </DIV>\n  <DIV class="datepages"> November 2007'
         b', pages 145-148</DIV>\n  <DIV class="download">  \n  \t<A href="htt'
         b'p://doi.acm.org/10.1145/1315184.1315210"><IMG src="../icons/acm32.pn'
         b'g"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRS'
         b'T_07.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://w'
         b'eb4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRST_07_Bib.htm"><IMG src="../ico'
         b'ns/bibtex32.png"></A>     \n    </DIV>   \n  <!-- <DIV class="abst'
         b'ract" name="abstract"> Global illumination in VR applications remain'
         b's an elusive goal. While it potentially has a positive impact on pre'
         b'sence, the significant real-time computation and integration complex'
         b'ities involved have been stumbling blocks. In this paper we present '
         b'recent and ongoing work in the Virtual Light Field paradigm for glob'
         b'al illumination as a solution to this problem. We discuss its suitab'
         b'ility for real-time VR applications and detail recent work in integr'
         b'ating it with the XVR system for real-time GPU-based rendering in a '
         b'CAVE(TM). This rendering method achieves real-time rendering of L(S|'
         b'D)* solutions in time independent of illumination complexity and lar'
         b'gely independent of geometric complexity. </DIV>-->\n  </DIV>\n\n\n<'
         b'DIV class="entry">\n  <DIV class="image" name="image"><IMG src=".'
         b'./pics/image07.jpg" alt="image"></DIV>\n  <DIV class="title"> A N'
         b'on-parametric Guide for Radiance Sampling in Global Illumination </D'
         b'IV>\n  <DIV class="author"> P. Khanna, M. Slater, J. Mortensen, I'
         b'. Yu</DIV>\n  <DIV class="proceedings"> CGIV \'07: Proceedings of '
         b'the Computer Graphics, Imaging and Visualisation </DIV>\n  <DIV c'
         b'lass="datepages">  2007, pages 41-48 </DIV>\n  <DIV class="downlo'
         b'ad">  \n  \t<A href="http://dx.doi.org/10.1109/CGIV.2007.9"><IMG s'
         b'rc="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk'
         b'/staff/i.yu/pub/Yu_CGIV_07a.pdf"><IMG src="../icons/pdf32.png"></A> '
         b'\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07a_B'
         b'ib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   '
         b'  \n  <!-- <DIV class="abstract" name="abstract"> Global illumina'
         b'tion as described by the radiance and potential equations is essenti'
         b'ally a sampling problem. This sampling has two elements: "where\''
         b' to sample and "how\' to sample. In this paper we propose an alte'
         b'rnative method to non-parametrically simplify the problem of "wh'
         b"ere' in the general case. We present a solid angle based uniform sam"
         b'pling scheme with an efficient conservative cull of solid angles not'
         b' affecting the transfer of radiance between two surfaces. This const'
         b'ruction also provides a geometric area bounds within which a surface'
         b' can receive energy from another along directions contained in the s'
         b'olid angle. The technique can be used to illuminate a scene from a g'
         b'eneral emitter, including incident light fields. The method has seve'
         b'ral applications and advantages, with results showing good sampling '
         b'efficiency and speed. </DIV>-->\n  </DIV>\n\n\n<DIV class="entry'
         b'">\n  <DIV class="image" name="image"><IMG src="../pics/image08.j'
         b'pg" alt="image"></DIV>\n  <DIV class="title"> A Visibility Field '
         b'for Ray Tracing</DIV>\n  <DIV class="author"> J. Mortensen, P. Kh'
         b'anna, I. Yu, M. Slater</DIV>\n  <DIV class="proceedings"> CGIV \'0'
         b'7: Proceedings of the Computer Graphics, Imaging and Visualisation <'
         b'/DIV>\n  <DIV class="datepages">  2007, pages 54-61 </DIV>\n  <DIV'
         b' class="download">  \n  \t<A href="http://dx.doi.org/10.1109/CGIV.'
         b'2007.14"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://we'
         b'b4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07b.pdf"><IMG src="../icons/p'
         b'df32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pu'
         b'b/Yu_CGIV_07b.mp4"><IMG src="../icons/movie32.png"></A>         '
         b'\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07b_B'
         b'ib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   '
         b'\n  <!-- <DIV class="abstract" name="abstract"> This paper presen'
         b'ts a type of visibility data structure for accelerated ray tracing. '
         b'The visibility field is constructed by choosing a regular point subd'
         b'ivision over a hemisphere to obtain a set of directions. Correspondi'
         b'ng to each direction there is then a rectangular grid of parallel be'
         b'ams, with each beam referencing a set of identifiers corresponding t'
         b'o objects that intersect it. Objects lying along a beam are sorted u'
         b'sing a 1D BSP along the beam direction. The beam corresponding to an'
         b'y ray can be looked up in small constant time and the set of objects'
         b' corresponding to the beam can then be searched for intersection wit'
         b'h the ray using an optimised traversal strategy. This approach trade'
         b's off rendering speed for memory usage and pre-processing time. The '
         b'data structure is also very suitable for hemisphere integration task'
         b's due to its spherical nature and results for one such task - ambien'
         b't occlusion - are also presented. Results for several scenes with va'
         b'rious rendering methods are presented and compare favourably with a '
         b'well established approach, the single-ray coherent ray tracing appro'
         b'ach of Wald and Slusallek et al. </DIV>-->\n  </DIV>\n\n<DIV class='
         b'"entry">\n  <DIV class="image" name="image"><IMG src="../pics/ima'
         b'ge09.jpg" alt="image"></DIV>\n  <DIV class="title"> Presence in R'
         b'esponse to Dynamic Visual Realism: A Preliminary Report of An Experi'
         b'ment Study</DIV>\n  <DIV class="author"> P. Khanna, I. Yu, J. Mor'
         b'tensen, M. Slater</DIV>\n  <DIV class="proceedings"> VRST \'06: Pr'
         b'oceedings of the ACM symposium on Virtual reality software and techn'
         b'ology</DIV>\n  <DIV class="datepages">  2006, pages 364-367 </DIV'
         b'>\n    <DIV class="download">  \n  \t<A href="http://doi.acm.org/10'
         b'.1145/1180495.1180569"><IMG src="../icons/acm32.png"></A>\n\t<A hr'
         b'ef="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRST_06.pdf"><IMG src'
         b'="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/s'
         b'taff/i.yu/pub/Yu_VRST_06_Bib.htm"><IMG src="../icons/bibtex32.png"><'
         b'/A>     \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstra'
         b'ct"> This paper describes an experiment that examines the influence '
         b'of visual realism on reported presence. 33 participants experienced '
         b'two different renderings of a virtual environment that depicts a pit'
         b' in the centre of a room, in a head-tracked head-mounted display. Th'
         b'e environment was rendered using parallel ray tracing at 15fps,mbut '
         b'in one condition ray casting (RC) was used achieving a result equiva'
         b'lent to OpenGL based per-pixel local illumination, and in the second'
         b' full recursive ray tracing (RT). The participants were randomly all'
         b'ocated to two groups -- one that experienced RC first followed by RT'
         b', and the second group in the opposite order. Reported presence was '
         b'obtained by questionnaires following each session. The results indic'
         b"ate that reported presence, in terms of the 'sense of being there' w"
         b'as significantly higher for the RT than for the RC condition. </DIV>'
         b'-->\n  </DIV>\n\n<DIV class="entry">\n  <DIV class="image" name="ima'
         b'ge"><IMG src="../pics/image10.jpg" alt="image"></DIV>\n  <DIV cla'
         b'ss="title"> Fast Ray Tracing of Scenes with Unstructured Motion </DI'
         b'V>\n  <DIV class="author"> P. Khanna, J. Mortensen, I. Yu, M. Sla'
         b'ter</DIV>\n  <DIV class="proceedings"> SIGGRAPH \'04: ACM SIGGRAPH'
         b' 2004 Posters   </DIV>\n  <DIV class="datepages">  2004, pages 35'
         b' </DIV>\n  <DIV class="download">  \n  \t<A href="http://doi.acm.or'
         b'g/10.1145/1186415.1186456"><IMG src="../icons/acm32.png"></A>\n\t<'
         b'A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_SIGGRAPH_04.pdf">'
         b'<IMG src="../icons/pdf32.png"></A> \n  \t<A href="http://web4.cs.u'
         b'cl.ac.uk/staff/i.yu/pub/Yu_SIGGRAPH_04.mpg"><IMG src="../icons/movie'
         b'32.png"></A>     \n      \t<A href="http://web4.cs.ucl.ac.uk/staff'
         b'/i.yu/pub/Yu_SIGGRAPH_04_ppt.pdf"><IMG src="../icons/ppt32.png"></A>'
         b'     \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_SIGGR'
         b'APH_04_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    <'
         b'/DIV>   \n  <!-- <DIV class="abstract" name="abstract"> Ray traci'
         b'ng dynamically changing scenes with unstructured motion for animated'
         b' objects has long been a problem for ray-traversal acceleration sche'
         b'mes. When polygons are transformed independently of one another, the'
         b' cost of updating traditional spatial data-structures can be quite h'
         b'igh [2001]. We propose a ray traversal scheme that is well suited to'
         b' scenes with dynamically changing objects during ray tracing. A simi'
         b'lar data structure for propagation and walkthrough only rendering of'
         b' globally illuminated scenes was introduced for global illumination '
         b'in [2004]. Here we concentrate on an application and modification of'
         b' that data structure for the task of ray tracing scenes composed of '
         b'static and dynamic objects. The major computation for handling arbit'
         b'rary transformations of dynamic objects reduces to low resolution 2D'
         b' polygon rasterisation.  </DIV>-->\n  </DIV>\n\n\n<DIV class="entry"'
         b'>\n  <DIV class="image" name="image"><IMG src="../pics/image11.jp'
         b'g" alt="image"></DIV>\n  <DIV class="title"> A Virtual Light Fiel'
         b'd Approach to Global Illumination </DIV>\n  <DIV class="author"> '
         b'M. Slater, J. Mortensen, P. Khanna, I. Yu, </DIV>\n  <DIV class="'
         b'proceedings"> CGI \'04: Proceedings of the Computer Graphics Inte'
         b'rnational </DIV>\n  <DIV class="datepages">  2004, pages 102-109 '
         b'</DIV>\n  <DIV class="download">  \n  \t<A href="http://dx.doi.org/'
         b'10.1109/CGI.2004.7"><IMG src="../icons/ieee32.png"></A>\n\t<A href'
         b'="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGI_04.pdf"><IMG src=".'
         b'./icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staf'
         b'f/i.yu/pub/Yu_CGI_04_Bib.htm"><IMG src="../icons/bibtex32.png"></A> '
         b'    \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstract">'
         b' This paper describes an algorithm that providesreal-time walkthroug'
         b'h for globally illuminated scenesthat contain mixtures of ideal diff'
         b'use and specularsurfaces. A type of light field data structure is us'
         b'ed forpropagating radiance outward from light emittersthrough the sc'
         b'ene, accounting for any kind of L(S|D)*light path. The light field e'
         b'mployed is constructed bychoosing a regular point subdivision over a'
         b'hemisphere, to give a set of directions, and thencorresponding to ea'
         b'ch direction there is a rectangulargrid of parallel rays. Each recta'
         b'ngular grid of rays isfurther subdivided into rectangular tiles, suc'
         b'h thateach tile references a sequence of 2D imagescontaining colour '
         b'values corresponding to theoutgoing radiances of surfaces intersecte'
         b'd by the raysin that tile. This structure is then used for final ima'
         b'gerendering. Propagation times can be very long and thememory requir'
         b'ements very high. This algorithm,however, offers a global illuminati'
         b'on solution for real-timewalkthrough even on a single processor.  </'
         b'DIV>-->\n  </DIV>\n\n<DIV class="year"></DIV>\n\n\n\n<DIV class="en'
         b'try">\n  <DIV class="image" name="image"><IMG src="../pics/image1'
         b'2.jpg" alt="image"></DIV>\n  <DIV class="title"> A Visibility Fie'
         b'ld for Dynamic Ray Tracing </DIV>\n  <DIV class="author"> P. Khan'
         b'na, J. Mortensen, I. Yu, M. Slater, </DIV>\n  <DIV class="proceed'
         b'ings"> Technical Report, University College London </DIV>\n  <DIV'
         b' class="datepages">  2005 </DIV>\n    <DIV class="download">  \n  '
         b'  <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TechReport_05a'
         b'.pdf"><IMG src="../icons/pdf32.png"></A>\n  </DIV>\n  <!-- <DIV cl'
         b'ass="abstract" name="abstract"> We have invented a new ray traversal'
         b' scheme that is especially suitable for dynamically changing objects'
         b' during image generation with ray tracing. This algorithm has recent'
         b'ly been introduced for walkthrough [Mortensen, et al. 2004], and it '
         b'compared favourably with the leading algorithm in the field, Coheren'
         b't Ray Tracing [Wald et al., 2001], at least in the case of non-paral'
         b'lel single ray processing. Here we only concentrate on dynamic chang'
         b'es to objects. Our approach supports dynamic object changes in a ver'
         b'y simple way since the major operation in the algorithm is only 2D p'
         b'olygon rasterisation at very low resolutions. At the moment our impl'
         b'ementation is single processor, and does not make use of the graphic'
         b's hardware, nevertheless the results are promising.  </DIV> -->\n'
         b'  </DIV>\n  \n <DIV class="entry">\n  <DIV class="image" name="imag'
         b'e"><IMG src="../pics/image13.jpg" alt="image"></DIV>\n  <DIV clas'
         b's="title"> Fast Ray Tracing of Scenes with Unstructured Motion </DIV'
         b'>\n  <DIV class="author"> P. Khanna, J. Mortensen, I. Yu, M. Slat'
         b'er, </DIV>\n  <DIV class="proceedings"> Technical Report, Univers'
         b'ity College London </DIV>\n  <DIV class="datepages">  2005 </DIV>'
         b'\n    <DIV class="download">  \n    <A href="http://web4.cs.ucl.ac'
         b'.uk/staff/i.yu/pub/Yu_TechReport_05b.pdf"><IMG src="../icons/pdf32.p'
         b'ng"></A>     \n  </DIV>\n  <!-- <DIV class="abstract" name="abstra'
         b'ct"> Ray tracing dynamically changing scenes with unstructured motio'
         b'n for animated objects has long been a problem for ray-traversal acc'
         b'eleration schemes. When polygons are transformed independently of on'
         b'e another, the cost of updating traditional spatial data-structures '
         b'can be quite high [Lext et al., 2001] [Wald et al., 2003]. We propos'
         b'e a ray traversal scheme that is well suited to scenes with dynamica'
         b'lly changing objects during ray tracing. A similar data structure fo'
         b'r propagation and walkthrough only rendering of globally illuminated'
         b' scenes was introduced for global illumination in [Slater et al., 20'
         b'04]. Here we concentrate on an application and modification of that '
         b'data structure for the task of ray tracing scenes composed of static'
         b' and dynamic objects. The major computation for handling arbitrary t'
         b'ransformations of dynamic objects reduces to low resolution 2D polyg'
         b'on rasterisation.  </DIV> -->\n  </DIV>\n  \n<DIV class="entry">\n  '
         b'<DIV class="image" name="image"><IMG src="../pics/image14.jpg" alt="'
         b'image"></DIV>\n  <DIV class="title"> A Virtual Light Field for Pr'
         b'opagation and Walkthrough of Globally Illuminated Scenes </DIV>\n'
         b'  <DIV class="author"> P. Khanna, M. Slater, J. Mortensen, I. Yu, </'
         b'DIV>\n  <DIV class="proceedings"> Technical Report, University Co'
         b'llege London </DIV>\n  <DIV class="datepages">  2004 </DIV>\n  <DI'
         b'V class="download">  \n    <A href="http://web4.cs.ucl.ac.uk/staf'
         b'f/i.yu/pub/Yu_TechReport_04.pdf"><IMG src="../icons/pdf32.png"></A> '
         b'   \n  </DIV>\n  <!-- <DIV class="abstract" name="abstract"> This '
         b'paper describes an algorithm that provides real-time walkthrough for'
         b' globally illuminated scenes comprising of ideal diffuse and specula'
         b'r polygonal surfaces. A type of light field data structure is used f'
         b'or propagating radiance outward from light emitters through the scen'
         b'e and accounts for all L(S|D)* light paths. The light field employed'
         b' is constructed by choosing a regular point subdivision over a hemis'
         b'phere, to give a set of directions, and then corresponding to each d'
         b'irection creating a rectangular grid of parallel rays. Each rectangu'
         b'lar grid of rays, called a \x91parallel subfield\x92 is further su'
         b'bdivided into rectangular tiles, such that each tile references a se'
         b'quence of 2D \x93images\x94 containing colour values corresponding'
         b' to the outgoing radiances of surfaces intersected by the rays belon'
         b'ging to that tile. Following propagation, this structure is used for'
         b' final image rendering. Propagation times are currently very long an'
         b'd the memory requirements high. This algorithm, however, offers a gl'
         b'obal illumination solution for real-time walkthrough even on a singl'
         b'e processor.  </DIV> -->\n  </DIV>\n  \n  \n<DIV class="year"></DIV>'
         b'\n\n  <DIV class="entry">\n  <DIV class="image" name="image"> <IMG '
         b'src="../pics/image15.jpg" alt="image">   </DIV>\n  <DIV class="ti'
         b'tle">  Perceptual Study of Indirect illumination</DIV>\n  <DIV cl'
         b'ass="author">  Insu Yu </DIV>\n  <DIV class="proceedings"> Invite'
         b'd talk, <a href="http://www.eventlab-ub.org/">EVENT Lab</a>, <a href'
         b'="http://www.ub.edu/">University of Barcelona</a></DIV>  \n  <DIV'
         b' class="datepages">  27 May 2010  </DIV>\n  <DIV class="download"'
         b'>  \n  \t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_Talk_'
         b'10.pptx"><IMG src="../icons/ppt32.png"></A>\n\t  <A href="http://w'
         b'eb4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_Talk_10_video1.wmv"><IMG src="../'
         b'icons/movie32.png"></A>          \n\t  <A href="http://web4.cs.ucl'
         b'.ac.uk/staff/i.yu/pub/Yu_Talk_10_video2.wmv"><IMG src="../icons/movi'
         b'e32.png"></A>\n\t  <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pu'
         b'b/Yu_Talk_10_video3.wmv"><IMG src="../icons/movie32.png"></A>\n  '
         b'  </DIV> \n\n<!-- tracker -->\n<SCRIPT src="./taglinks.js" type="te'
         b'xt/javascript"></SCRIPT>\n<SCRIPT type="text/javascript">\n_uacct '
         b'= "UA-66354-2";\nurchinTracker();\n</SCRIPT>\n\n\n\n</BODY></HTML>',
 'links': [3301,
           3353,
           3303,
           3304,
           3305,
           3354,
           3355,
           3356,
           3357,
           3358,
           3359,
           3360,
           3361,
           3362,
           3363],
 'pid': 3302,
 'url': 'http://web4.cs.ucl.ac.uk/staff/i.yu/publications/'}