{'html': '<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">\n<!-- saved from url=(0051)http://web4.cs.ucl.ac.uk/staff/i.yu/publications/ -->\n<HTML><HEAD><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">\n   \n   <META name="GENERATOR" content="Mozilla/4.7 [en] (X11; U; IRIX 6.5 IP32) [Netscape]">\n   <TITLE>Publications</TITLE>\n   <LINK href="./general.css" rel="stylesheet" type="text/css">\n   <LINK href="./publications.css" rel="stylesheet" type="text/css">\n   <LINK rel="icon" href="http://web4.cs.ucl.ac.uk/staff/i.yu/pics/JK.ico">\n   <LINK rel="SHORTCUT ICON" href="http://web4.cs.ucl.ac.uk/staff/i.yu/pics/JK.ico">\n<SCRIPT src="./urchin.js" type="text/javascript"></SCRIPT><SCRIPT src="./prototype.js" type="text/javascript"></SCRIPT><SCRIPT src="./scriptaculous.js" type="text/javascript"></SCRIPT><SCRIPT type="text/javascript" src="./builder.js"></SCRIPT><SCRIPT type="text/javascript" src="./effects.js"></SCRIPT><SCRIPT type="text/javascript" src="./dragdrop.js"></SCRIPT><SCRIPT type="text/javascript" src="./controls.js"></SCRIPT><SCRIPT type="text/javascript" src="./slider.js"></SCRIPT><SCRIPT type="text/javascript" src="./sound.js"></SCRIPT></HEAD><BODY>\n\n<SCRIPT type="text/javascript">\n<!--\n// from Jonathan Snook: www.snook.ca\nfunction getElementsByClassName(node, classname)\n{\n    var a = [];\n    var re = new RegExp(\'\\\\b\' + classname + \'\\\\b\');\n    var els = node.getElementsByTagName("*");\n    for(var i=0,j=els.length; i<j; i++)\n        if(re.test(els[i].className))a.push(els[i]);\n    return a;\n}\n\nvar toggle = 0;\nfunction toggleStyle() \n{\n  toggle = 1 - toggle;\n//  document.all[\'image\'].style.display = toggle ? \'none\' : \'block\';\n// document.all[\'abstract\'].style.display = toggle ? \'none\' : \'block\';\n\n  // get rid of abstracts\n  abstracts = getElementsByClassName(document,\'abstract\');\n  for(var i = 0; i < abstracts.length; i++) {\n   // abstracts[i].style.display = toggle ? \'none\' : \'block\';\n   abstracts[i].style.display = \'block\';\n   if( !toggle ) Effect.BlindDown(abstracts[i]);\n   else Effect.BlindUp(abstracts[i]);\n  }\n\n  // get rid of images\n  images = getElementsByClassName(document,\'image\');\n  for(var i = 0; i < images.length; i++) {\n   //-> HIDE\n   //images[i].style.display = toggle ? \'none\' : \'block\';\n   //-> FANCY: scale them...\n   //var image = images[i].getElementsByTagName( \'img\' );\n   //image[0].style.width = toggle ? \'80px\' : \'190px\';\n   //image[0].style.height = \'auto\';\n  }\n}\n//-->\n</SCRIPT>\n\n               \n<DIV id="main">\n<DIV id="header">\n <DIV id="headerentry">publi</DIV><DIV id="headerentry2">cations</DIV>\n</DIV>\n<DIV id="navigator">\n<UL>\n<LI><A class="home" href="http://web4.cs.ucl.ac.uk/staff/i.yu/"><SPAN>home</SPAN></A></LI>\n<LI><A class="publications" href="http://web4.cs.ucl.ac.uk/staff/i.yu/publications"><SPAN>publications</SPAN></A></LI>\n<LI><A class="teaching" href="http://web4.cs.ucl.ac.uk/staff/i.yu/teaching/"><SPAN>teaching</SPAN></A></LI>\n<LI><A class="links" href="http://web4.cs.ucl.ac.uk/staff/i.yu/links/"><SPAN>links</SPAN></A></LI>\n<LI><A class="contact" href="http://web4.cs.ucl.ac.uk/staff/i.yu/contact/"><SPAN>about</SPAN></A></LI>\n</UL>\n</DIV>\n      \n\n<DIV id="content">\n<DIV class="section">Publications\n<FONT size="-2"><A href="javascript:toggleStyle();">toggle abstracts</A></FONT> </DIV>\n<DIV class="year"></DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"> <IMG src="../pics/image01.jpg" alt="image">   </DIV>\n  <DIV class="title">  Visual Realism Enhances Realistic Response in An Immersive Virtual Environment - Part2 (Feature Article)</DIV>\n  <DIV class="author">  I. Yu, J. Mortensen, P. Khanna,B. Spanlang and M. Slater   </DIV>\n  <DIV class="journal">   <IMG src="../icons/journal.png"> IEEE Computer Graphics and Applications - ISI Impact Factor: 1.8 </DIV>\n  <DIV class="datepages">   ISSN:0272-1716,  32(7), Nov.-Dec. 2012, pages 36-45</DIV>\n    <DIV class="download">  \n  \t<A href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6353430"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_12.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_12_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV> \n  <!-- <DIV class="abstract" name="abstract">  Does realistic lighting in an immersive virtual reality application enhance presence, where participants feel that they are in the scene and behave correspondingly? Our previous study indicated that presence is more likely with real-time ray tracing compared with ray casting, but we could not separate the effects of overall quality of illumination from the dynamic effects of real-time shadows and reflections. Here we describe an experiment where 20 people experienced a scene rendered with global or local illumination. However, in both conditions there were dynamically changing shadows and reflections. We found that the quality of illumination did not impact presence, so that the earlier result must have been due to dynamic shadows and reflections. However, global illumination resulted in greater plausibility - participants were more likely to respond as if the virtual events were real. We conclude that global illumination does impact the responses of participants and is worth the effort.</DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image02.jpg" alt="image"></DIV>\n  <DIV class="title"> Display-aware Image Editing </DIV>\n  <DIV class="author"> Won-Ki Jeong, Micah K. Johnson, Insu Yu, Jan Kautz, Hanspeter Pfister, and Sylvain Paris </DIV>\n  <DIV class="proceedings"> IEEE International Conference on Computional Photography (ICCP) </DIV>\n  <DIV class="datepages">  April 2011, pages 1-8 </DIV>\n  <DIV class="download"> \n  <A href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5753125"><IMG src="../icons/ieee32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_ICCP_11.pdf"><IMG src="../icons/pdf32.png"></A> \n  <A href="http://web4.cs.ucl.ac.uk/staff/j.kautz/videos/Display-aware_Image_Editing.mov"><IMG src="../icons/movie32.png"></A>\t     \n    </DIV>     \n  <!--<DIV class="abstract" name="abstract"> We describe a set of image editing and viewing tools that explicitly take into account the resolution of the display on which the image is viewed. Our approach is twofold. First, we design editing tools that process only the visible data, which is useful for images larger than the display. This encompasses cases such as multi-image panoramas and high-resolution medical data. Second, we propose an adaptive way to set viewing parameters such brightness and contrast. Because we deal with very large images, different locations and scales often require different viewing parameters. We let users set these parameters at a few places and interpolate satisfying values everywhere else. We demonstrate the efficiency of our approach on different display and image sizes. Since the computational complexity to render a view depends on the display resolution and not the actual input image resolution, we achieve interactive image editing even on a 16 gigapixel image. </DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"> <IMG src="../pics/image03.jpg" alt="image">   </DIV>\n  <DIV class="title">  Perceptual Influence of Approximate Visibility in Indirect Illumination  </DIV>\n  <DIV class="author">  I. Yu, A. Cox, M. H. Kim, T. Ritschel, T. Grosch, C. Dachsbacher, J. Kautz  </DIV>\n  <DIV class="journal">  <IMG src="../icons/journal.png"> ACM Transactions on Applied Perception (Presented at APGV 2009) - ISI Impact Factor: 1.44</DIV>\n  <DIV class="datepages">  ISSN:1544-3558, 6(4), September 2009, pages 24:1-24:14</DIV>\n  <DIV class="download">  \n  \t<A href="http://doi.acm.org/10.1145/1620993.1609971"><IMG src="../icons/acm32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TAP_09.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TAP_09.mov"><IMG src="../icons/movie32.png"></A>     \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TAP_09_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>\n   <!--<DIV class="abstract" name="abstract"> In this paper we evaluate the use of approximate visibility for efficient global illumination. Traditionally, accurate visibility is used in light transport. However, the indirect illumination we perceive on a daily basis is rarely of high frequency nature, as the most significant aspect of light transport in real-world scenes is diffuse, and thus displays a smooth gradation. This raises the question of whether accurate visibility is perceptually necessary in this case. To answer this question, we conduct a psychophysical study on the perceptual influence of approximate visibility on indirect illumination. This study reveals that accurate visibility is not required and that certain approximations may be introduced.</DIV>-->\n   </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"> <IMG src="../pics/image04.jpg" alt="image">   </DIV>\n  <DIV class="title">  Visual Realism Enhances Realistic Response in An Immersive Virtual Environment (Feature Article) </DIV>\n  <DIV class="author">  M. Slater, P. Khanna, J. Mortensen, I. Yu  </DIV>\n  <DIV class="journal">   <IMG src="../icons/journal.png"> IEEE Computer Graphics and Applications - ISI Impact Factor: 1.76</DIV>\n  <DIV class="datepages">  ISSN:0272-1716,  29(3), May 2009, pages 76-84 </DIV>\n    <DIV class="download">  \n  \t<A href="http://dx.doi.org/10.1109/MCG.2009.55"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_09.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_09_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV> \n  <!--<DIV class="abstract" name="abstract"> Does greater visual realism induce greater participant presence in immersive virtual environments (VE)? Presence refers to how realistically participants respond to the environment as well as their subjective sense of being in the place depicted by the VE. Thirty-three people were exposed for three minutes to a virtual environment depicting a precipice using a head-tracked head-mounted display system. Seventeen of them saw the environment rendered with real-time recursive ray tracing (RT) that included shadows and reflections of their virtual body, and the remainder experienced the same environment rendered with ray casting (RC), which did not include shadows and reflections. Participants completed a presence questionnaire immediately after their experience, and physiological responses (skin conductance and electrocardiogram) were recorded throughout. Results show that subjective presence was higher for the RT environment than for the RC one and that higher stress was induced in the RT environment compared to the RC one.</DIV> -->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"> <IMG src="../pics/image05.jpg" alt="image">   </DIV>\n  <DIV class="title">  Real-Time Global Illumination for VR Applications </DIV>\n  <DIV class="author">  J. Mortensen, I. Yu, P. Khanna, M. Slater, F. Tecchia, B. Spanlang, G. Marino, M. Slater </DIV> \n  <DIV class="journal">  <IMG src="../icons/journal.png"> IEEE Computer Graphics and Applications - ISI Impact Factor: 1.87 </DIV>\n  <DIV class="datepages"> ISSN:0272-1716,  28(6), November 2008, pages 56-64 </DIV>\n  <DIV class="download">  \n  \t<A href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4670101"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_08.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_IEEE_08_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV> \n  <!-- <DIV class="abstract" name="abstract"> Real-time global illumination in VR systems enhances scene realism by incorporating soft shadows, reflections of objects in the scene, and color bleeding. The Virtual Light Field (VLF) method enables real-time global illumination rendering in VR. The VLF has been integrated with the Extreme VR system for real-time GPU-based rendering in a Cave Automatic Virtual Environment.</DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image06.jpg" alt="image"></DIV>\n  <DIV class="title"> Real-time Global Illumination in the CAVE </DIV>\n  <DIV class="author"> J. Mortensen, P. Khanna, I. Yu, M. Slater </DIV>\n  <DIV class="proceedings"> VRST \'07: Proceedings of the 2007 ACM symposium on Virtual reality software and technology </DIV>\n  <DIV class="datepages"> November 2007, pages 145-148</DIV>\n  <DIV class="download">  \n  \t<A href="http://doi.acm.org/10.1145/1315184.1315210"><IMG src="../icons/acm32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRST_07.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRST_07_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstract"> Global illumination in VR applications remains an elusive goal. While it potentially has a positive impact on presence, the significant real-time computation and integration complexities involved have been stumbling blocks. In this paper we present recent and ongoing work in the Virtual Light Field paradigm for global illumination as a solution to this problem. We discuss its suitability for real-time VR applications and detail recent work in integrating it with the XVR system for real-time GPU-based rendering in a CAVE(TM). This rendering method achieves real-time rendering of L(S|D)* solutions in time independent of illumination complexity and largely independent of geometric complexity. </DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image07.jpg" alt="image"></DIV>\n  <DIV class="title"> A Non-parametric Guide for Radiance Sampling in Global Illumination </DIV>\n  <DIV class="author"> P. Khanna, M. Slater, J. Mortensen, I. Yu</DIV>\n  <DIV class="proceedings"> CGIV \'07: Proceedings of the Computer Graphics, Imaging and Visualisation </DIV>\n  <DIV class="datepages">  2007, pages 41-48 </DIV>\n  <DIV class="download">  \n  \t<A href="http://dx.doi.org/10.1109/CGIV.2007.9"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07a.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07a_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>     \n  <!-- <DIV class="abstract" name="abstract"> Global illumination as described by the radiance and potential equations is essentially a sampling problem. This sampling has two elements: "where\' to sample and "how\' to sample. In this paper we propose an alternative method to non-parametrically simplify the problem of "where\' in the general case. We present a solid angle based uniform sampling scheme with an efficient conservative cull of solid angles not affecting the transfer of radiance between two surfaces. This construction also provides a geometric area bounds within which a surface can receive energy from another along directions contained in the solid angle. The technique can be used to illuminate a scene from a general emitter, including incident light fields. The method has several applications and advantages, with results showing good sampling efficiency and speed. </DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image08.jpg" alt="image"></DIV>\n  <DIV class="title"> A Visibility Field for Ray Tracing</DIV>\n  <DIV class="author"> J. Mortensen, P. Khanna, I. Yu, M. Slater</DIV>\n  <DIV class="proceedings"> CGIV \'07: Proceedings of the Computer Graphics, Imaging and Visualisation </DIV>\n  <DIV class="datepages">  2007, pages 54-61 </DIV>\n  <DIV class="download">  \n  \t<A href="http://dx.doi.org/10.1109/CGIV.2007.14"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07b.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07b.mp4"><IMG src="../icons/movie32.png"></A>         \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGIV_07b_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstract"> This paper presents a type of visibility data structure for accelerated ray tracing. The visibility field is constructed by choosing a regular point subdivision over a hemisphere to obtain a set of directions. Corresponding to each direction there is then a rectangular grid of parallel beams, with each beam referencing a set of identifiers corresponding to objects that intersect it. Objects lying along a beam are sorted using a 1D BSP along the beam direction. The beam corresponding to any ray can be looked up in small constant time and the set of objects corresponding to the beam can then be searched for intersection with the ray using an optimised traversal strategy. This approach trades off rendering speed for memory usage and pre-processing time. The data structure is also very suitable for hemisphere integration tasks due to its spherical nature and results for one such task - ambient occlusion - are also presented. Results for several scenes with various rendering methods are presented and compare favourably with a well established approach, the single-ray coherent ray tracing approach of Wald and Slusallek et al. </DIV>-->\n  </DIV>\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image09.jpg" alt="image"></DIV>\n  <DIV class="title"> Presence in Response to Dynamic Visual Realism: A Preliminary Report of An Experiment Study</DIV>\n  <DIV class="author"> P. Khanna, I. Yu, J. Mortensen, M. Slater</DIV>\n  <DIV class="proceedings"> VRST \'06: Proceedings of the ACM symposium on Virtual reality software and technology</DIV>\n  <DIV class="datepages">  2006, pages 364-367 </DIV>\n    <DIV class="download">  \n  \t<A href="http://doi.acm.org/10.1145/1180495.1180569"><IMG src="../icons/acm32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRST_06.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_VRST_06_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstract"> This paper describes an experiment that examines the influence of visual realism on reported presence. 33 participants experienced two different renderings of a virtual environment that depicts a pit in the centre of a room, in a head-tracked head-mounted display. The environment was rendered using parallel ray tracing at 15fps,mbut in one condition ray casting (RC) was used achieving a result equivalent to OpenGL based per-pixel local illumination, and in the second full recursive ray tracing (RT). The participants were randomly allocated to two groups -- one that experienced RC first followed by RT, and the second group in the opposite order. Reported presence was obtained by questionnaires following each session. The results indicate that reported presence, in terms of the \'sense of being there\' was significantly higher for the RT than for the RC condition. </DIV>-->\n  </DIV>\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image10.jpg" alt="image"></DIV>\n  <DIV class="title"> Fast Ray Tracing of Scenes with Unstructured Motion </DIV>\n  <DIV class="author"> P. Khanna, J. Mortensen, I. Yu, M. Slater</DIV>\n  <DIV class="proceedings"> SIGGRAPH \'04: ACM SIGGRAPH 2004 Posters   </DIV>\n  <DIV class="datepages">  2004, pages 35 </DIV>\n  <DIV class="download">  \n  \t<A href="http://doi.acm.org/10.1145/1186415.1186456"><IMG src="../icons/acm32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_SIGGRAPH_04.pdf"><IMG src="../icons/pdf32.png"></A> \n  \t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_SIGGRAPH_04.mpg"><IMG src="../icons/movie32.png"></A>     \n      \t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_SIGGRAPH_04_ppt.pdf"><IMG src="../icons/ppt32.png"></A>     \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_SIGGRAPH_04_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstract"> Ray tracing dynamically changing scenes with unstructured motion for animated objects has long been a problem for ray-traversal acceleration schemes. When polygons are transformed independently of one another, the cost of updating traditional spatial data-structures can be quite high [2001]. We propose a ray traversal scheme that is well suited to scenes with dynamically changing objects during ray tracing. A similar data structure for propagation and walkthrough only rendering of globally illuminated scenes was introduced for global illumination in [2004]. Here we concentrate on an application and modification of that data structure for the task of ray tracing scenes composed of static and dynamic objects. The major computation for handling arbitrary transformations of dynamic objects reduces to low resolution 2D polygon rasterisation.  </DIV>-->\n  </DIV>\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image11.jpg" alt="image"></DIV>\n  <DIV class="title"> A Virtual Light Field Approach to Global Illumination </DIV>\n  <DIV class="author"> M. Slater, J. Mortensen, P. Khanna, I. Yu, </DIV>\n  <DIV class="proceedings"> CGI \'04: Proceedings of the Computer Graphics International </DIV>\n  <DIV class="datepages">  2004, pages 102-109 </DIV>\n  <DIV class="download">  \n  \t<A href="http://dx.doi.org/10.1109/CGI.2004.7"><IMG src="../icons/ieee32.png"></A>\n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGI_04.pdf"><IMG src="../icons/pdf32.png"></A> \n\t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_CGI_04_Bib.htm"><IMG src="../icons/bibtex32.png"></A>     \n    </DIV>   \n  <!-- <DIV class="abstract" name="abstract"> This paper describes an algorithm that providesreal-time walkthrough for globally illuminated scenesthat contain mixtures of ideal diffuse and specularsurfaces. A type of light field data structure is used forpropagating radiance outward from light emittersthrough the scene, accounting for any kind of L(S|D)*light path. The light field employed is constructed bychoosing a regular point subdivision over ahemisphere, to give a set of directions, and thencorresponding to each direction there is a rectangulargrid of parallel rays. Each rectangular grid of rays isfurther subdivided into rectangular tiles, such thateach tile references a sequence of 2D imagescontaining colour values corresponding to theoutgoing radiances of surfaces intersected by the raysin that tile. This structure is then used for final imagerendering. Propagation times can be very long and thememory requirements very high. This algorithm,however, offers a global illumination solution for real-timewalkthrough even on a single processor.  </DIV>-->\n  </DIV>\n\n<DIV class="year"></DIV>\n\n\n\n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image12.jpg" alt="image"></DIV>\n  <DIV class="title"> A Visibility Field for Dynamic Ray Tracing </DIV>\n  <DIV class="author"> P. Khanna, J. Mortensen, I. Yu, M. Slater, </DIV>\n  <DIV class="proceedings"> Technical Report, University College London </DIV>\n  <DIV class="datepages">  2005 </DIV>\n    <DIV class="download">  \n    <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TechReport_05a.pdf"><IMG src="../icons/pdf32.png"></A>\n  </DIV>\n  <!-- <DIV class="abstract" name="abstract"> We have invented a new ray traversal scheme that is especially suitable for dynamically changing objects during image generation with ray tracing. This algorithm has recently been introduced for walkthrough [Mortensen, et al. 2004], and it compared favourably with the leading algorithm in the field, Coherent Ray Tracing [Wald et al., 2001], at least in the case of non-parallel single ray processing. Here we only concentrate on dynamic changes to objects. Our approach supports dynamic object changes in a very simple way since the major operation in the algorithm is only 2D polygon rasterisation at very low resolutions. At the moment our implementation is single processor, and does not make use of the graphics hardware, nevertheless the results are promising.  </DIV> -->\n  </DIV>\n  \n <DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image13.jpg" alt="image"></DIV>\n  <DIV class="title"> Fast Ray Tracing of Scenes with Unstructured Motion </DIV>\n  <DIV class="author"> P. Khanna, J. Mortensen, I. Yu, M. Slater, </DIV>\n  <DIV class="proceedings"> Technical Report, University College London </DIV>\n  <DIV class="datepages">  2005 </DIV>\n    <DIV class="download">  \n    <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TechReport_05b.pdf"><IMG src="../icons/pdf32.png"></A>     \n  </DIV>\n  <!-- <DIV class="abstract" name="abstract"> Ray tracing dynamically changing scenes with unstructured motion for animated objects has long been a problem for ray-traversal acceleration schemes. When polygons are transformed independently of one another, the cost of updating traditional spatial data-structures can be quite high [Lext et al., 2001] [Wald et al., 2003]. We propose a ray traversal scheme that is well suited to scenes with dynamically changing objects during ray tracing. A similar data structure for propagation and walkthrough only rendering of globally illuminated scenes was introduced for global illumination in [Slater et al., 2004]. Here we concentrate on an application and modification of that data structure for the task of ray tracing scenes composed of static and dynamic objects. The major computation for handling arbitrary transformations of dynamic objects reduces to low resolution 2D polygon rasterisation.  </DIV> -->\n  </DIV>\n  \n<DIV class="entry">\n  <DIV class="image" name="image"><IMG src="../pics/image14.jpg" alt="image"></DIV>\n  <DIV class="title"> A Virtual Light Field for Propagation and Walkthrough of Globally Illuminated Scenes </DIV>\n  <DIV class="author"> P. Khanna, M. Slater, J. Mortensen, I. Yu, </DIV>\n  <DIV class="proceedings"> Technical Report, University College London </DIV>\n  <DIV class="datepages">  2004 </DIV>\n  <DIV class="download">  \n    <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_TechReport_04.pdf"><IMG src="../icons/pdf32.png"></A>    \n  </DIV>\n  <!-- <DIV class="abstract" name="abstract"> This paper describes an algorithm that provides real-time walkthrough for globally illuminated scenes comprising of ideal diffuse and specular polygonal surfaces. A type of light field data structure is used for propagating radiance outward from light emitters through the scene and accounts for all L(S|D)* light paths. The light field employed is constructed by choosing a regular point subdivision over a hemisphere, to give a set of directions, and then corresponding to each direction creating a rectangular grid of parallel rays. Each rectangular grid of rays, called a \x91parallel subfield\x92 is further subdivided into rectangular tiles, such that each tile references a sequence of 2D \x93images\x94 containing colour values corresponding to the outgoing radiances of surfaces intersected by the rays belonging to that tile. Following propagation, this structure is used for final image rendering. Propagation times are currently very long and the memory requirements high. This algorithm, however, offers a global illumination solution for real-time walkthrough even on a single processor.  </DIV> -->\n  </DIV>\n  \n  \n<DIV class="year"></DIV>\n\n  <DIV class="entry">\n  <DIV class="image" name="image"> <IMG src="../pics/image15.jpg" alt="image">   </DIV>\n  <DIV class="title">  Perceptual Study of Indirect illumination</DIV>\n  <DIV class="author">  Insu Yu </DIV>\n  <DIV class="proceedings"> Invited talk, <a href="http://www.eventlab-ub.org/">EVENT Lab</a>, <a href="http://www.ub.edu/">University of Barcelona</a></DIV>  \n  <DIV class="datepages">  27 May 2010  </DIV>\n  <DIV class="download">  \n  \t<A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_Talk_10.pptx"><IMG src="../icons/ppt32.png"></A>\n\t  <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_Talk_10_video1.wmv"><IMG src="../icons/movie32.png"></A>          \n\t  <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_Talk_10_video2.wmv"><IMG src="../icons/movie32.png"></A>\n\t  <A href="http://web4.cs.ucl.ac.uk/staff/i.yu/pub/Yu_Talk_10_video3.wmv"><IMG src="../icons/movie32.png"></A>\n    </DIV> \n\n<!-- tracker -->\n<SCRIPT src="./taglinks.js" type="text/javascript"></SCRIPT>\n<SCRIPT type="text/javascript">\n_uacct = "UA-66354-2";\nurchinTracker();\n</SCRIPT>\n\n\n\n</BODY></HTML>',
 'pid': 242,
 'url': 'http://web4.cs.ucl.ac.uk/staff/i.yu/publications/'}