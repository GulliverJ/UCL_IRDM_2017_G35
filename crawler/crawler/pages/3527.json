{'html': b'<HTML><HEAD><TITLE>GI13/4C60: Advanced Topics in Machine Learning, S'
         b'pring 2005</TITLE>\n<META http-equiv=Content-Type content="text/h'
         b'tml; charset=windows-1252">\n<META content="MSHTML 6.00.2800.1106'
         b'" name=GENERATOR></HEAD>\n<BODY text=#000000 bgColor=#ffffff>\n<H1'
         b'>\n<CENTER>GI13/4C60: Advanced Topics in Machine Learning (Spring'
         b' 2005)</CENTER></H1>\n<HR>\n\n<BLOCKQUOTE>\n  <TABLE>\n    <TBODY'
         b'>\n    <TR>\n      <TD align=right><B>Class Times:</B></TD>\n      '
         b'<TD>Tuesday, 14:00-17:00, Friday 10:00-13:00</TD></TR>\n    <TR>\n'
         b'      <TD align=right><B>Location:</B></TD>\n      <TD>Computer S'
         b'cience Dept, Room 104</TD></TR>\n    <TR>\n      <TD align=right><'
         b'B>Instructors:</B></TD>\n      <TD><A href="http://www.cs.ucl.ac.'
         b'uk/staff/M.Pontil/">Massimiliano \n        Pontil </A></TD></TR>\n'
         b'    <TR><!--         <td align="right"><b>Office Hours:</b></td>'
         b'\n         <td></td>--></TR>\n    <TR>\n      <TD align=right><B>Em'
         b'ail Contact :</B></TD>\n      <TD><B><A \n    href="mailto:gi13@cs'
         b'.ucl.ac.uk">gi13@cs.ucl.ac.uk</A></B></TD></TR></TBODY></TABLE>\n'
         b'  <UL>\n    <LI><A \n    href="http://www.cs.ucl.ac.uk/staff/M.Pon'
         b'til/courses/index-ATML05.htm#description">Course \n    Descriptio'
         b'n</A> \n    <LI><A \n    href="http://www.cs.ucl.ac.uk/staff/M.Pon'
         b'til/courses/index-ATML05.htm#requirements">Prerequisites</A> \n\n '
         b'   <LI><A \n    href="http://www.cs.ucl.ac.uk/staff/M.Pontil/cour'
         b'ses/index-ATML05.htm#grading">Grading</A> \n\n    <LI><A \n    href'
         b'="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/index-ATML05.htm#ps'
         b'ets">In-class Presentations</A> \n    <LI><A \n    href="http://ww'
         b'w.cs.ucl.ac.uk/staff/M.Pontil/courses/index-ATML05.htm#briefsyllabus'
         b'">Syllabus</A> \n\n    <LI><A \n    href="http://www.cs.ucl.ac.uk/s'
         b'taff/M.Pontil/courses/index-ATML05.htm#readings">Reading List</A> </'
         b'LI></UL>\n  <H2><A name=description></A><B>Course description</B>'
         b'</H2>\nThe course presents the elements of kernel-based methods f'
         b'rom a machine learning \nperspective. It introduces the theoretic'
         b'al basis for studying these methods (theory of positive definite ker'
         b'nels, associated reproducing kernel Hilbert spaces and techniques to'
         b' construct kernel functions) and present \nselected topics in thi'
         b's area. This includes learning algorithms such as regularization net'
         b'works, support vector machines, \nkernel principal component anal'
         b'ysis, kernel canonical correlation analysis, anomaly detection, etc.'
         b', as well as a discussion of the value of \nthese algorithms for '
         b'applications.\n<!-- and the construction of kernels in-->\nThe mat'
         b'erial is primarily based on a recent book and on research publicatio'
         b'ns. \n<p>\n\nStudents should gain an in-depth familiarity with kern'
         b'el methods \nand be able to individually read and discuss in clas'
         b's research papers in the field.  \n\n<!--Students should develop a'
         b' detailed knowledge of a current area in machine learning \nresea'
         b'rch, develop knowledge and understanding of mathematical models and '
         b'\nalgorithmic implementations of these and understand theoretical'
         b' approaches and \npractical implications of current research in m'
         b'achine learning.-->\n\n  <H2><A name=requirements></A><B>Prerequis'
         b'ites</B></H2>A good background in\nuniversity-level mathematics ('
         b'calculus, elements of linear algebra and optimization), Supervised L'
         b'earning (4C55/GI01).\n  <H2><A name=grading></A><B>Grading</B></H'
         b'2>\nThe course has the following assessment components: 1) Writte'
         b'n Examination (2.5 hours, 50%); 2) Orally assessed coursework (24 ho'
         b'urs, 25%) Reports (24 hours, 25%).\n<p>\nTo pass this course, stud'
         b'ents must obtain at least 40% on the coursework component and an ave'
         b'rage of at least 50% when the coursework and exam components of a co'
         b'urse are \nweighted together.\n\n  <P></P>\n  <H2><A name=psets></A>'
         b'<B>In-class presentations</B></H2>\n\nEach student needs to choose'
         b' a topic, either based on a chapter/section from the course book or '
         b'a research paper (see list below). \n<!--(you can come up whit yo'
         b'ur own topic provided it is related to those below).-->\nS/he wil'
         b"l read and then prepare a presentation. \nThe presentation's aim "
         b'is to describe and explain the topic to the class \n(allowing for'
         b' questions). \nThe following are the requirements:\n<p>\n\n1. Topics'
         b' are allocated to students on a first-come first-get basis. \nTo '
         b'be allocated, a student needs to <A\n    href="mailto:m.pontil@cs'
         b'.ucl.ac.uk">send a request to the lecturer</A> stating the name '
         b'\nof the chosen topic. The list will be updated online to indicat'
         b'e which \ntopics are still available. Once a topic has been alloc'
         b'ated, there will \nbe no changes.\n\n<p>\n2. All requests for topic '
         b'allocation must be sent to the lecturer no later than \n12:00am, '
         b'Monday Jan 24, 2005. The first group of presentations will be on Feb'
         b' 4. The second group on Feb 11. \n\n<p>\n3. The presentation needs '
         b'to be done using power-point on a laptop (will be provided)\nor o'
         b'n a transparency-projector (preferably using Latex but handwriting i'
         b's o.k.\nprovided it is clear). The amount of material per slide s'
         b'hould be equivalent to\napproximately 2/4 minutes of presentation'
         b' time per slide. The time allocated for each presentation is 30-50 m'
         b'inutes.\n\n<p>\n4. The presentation material needs to be prepared i'
         b'n electronic format\nhaving 4 slides per page (preferably in .pdf'
         b' or .ps but PowerPoint is also\npossible) and sent to the lecture'
         b'r at least 48 hours prior to the\npresentation date. The dates/ti'
         b'mes of each presentation will be announced in class.\n\n<p>\n<TBODY'
         b'>\n<TABLE border=1>\n<TR>\n<TH>Title</TH>\n<TH>Who</TH>\n<TH>When'
         b'</TH>\n</TR>\n\n<TR>\n<TD>\nSingular value decomposition, Ch. 6.1'
         b' and proof of Prop. 6.12 \n</TD>\n<TD>Hassan</TD>\n<TD>Feb 4</TD>\n<'
         b'/TR>\n\n\n<TR>\n<TD>\nDirection of max covariance and generalized'
         b' eigenvalue problem, Ch. 6.3 6.4, pp 155-164\n</TD>\n<TD>Feng Yuan'
         b'</TD>\n<TD>Feb 4</TD>\n</TR>\n\n<TR>\n<TD>\nCanonical correlation '
         b'analysis, Ch. 6.5, pp 164-175\n</TD>\n<TD>Xi Chen</TD>\n<TD>Feb 11<'
         b'/TD>\n</TR>\n\n<TR>\n<TD>\nFisher discriminant analysis, Ch. 5.4,'
         b' pp 132-137\n</TD>\n<TD>Christopher</TD>\n<TD>Feb 11</TD>\n</TR>'
         b'\n\n<TR><TD>\nKernel perceptron algorithm, Ch. 7.4, pp 241-248\n</TD'
         b'>\n<TD>Phil</TD>\n<TD>Feb 4</TD>\n</TR>\n\n<TR><TD>\nNovelty detec'
         b'tion, Ch 7.1.1, 7.1.3\n</TD>\n<TD>Oliver</TD>\n<TD>Feb 4</TD>\n</TR>'
         b'\n\n<TR><TD>\nnu-support vector machine, Ch 7.2\n</TD>\n<TD>Stefa'
         b'nia</TD>\n<TD>Feb 11</TD>\n</TR>\n\n<TR><TD>\nSupport vector mach'
         b'ine regression, Ch 7.3.3\n</TD>\n<TD>Jia Zhou</TD>\n<TD>Feb 4</TD>\n'
         b'</TR>\n\n<TR><TD>\n<A href="http://www.cs.ucl.ac.uk/staff/M.Pontil/'
         b'courses/multi-task.pdf">\nRegularized multi-task learning\n</A>\n</'
         b'TD>\n<TD>Sylvain</TD>\n<TD>Feb 11</TD>\n</TR>\n\n<TR><TD>\n<A href'
         b'="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/SVMprob.pdf">\nP'
         b'robabilistic outputs for SVMs\n</A>\n</TD>\n<TD>Cheng Yuan</TD>\n<TD'
         b'>Feb 11</TD>\n</TR>\n\n<TR><TD>\n<A href="http://www.cs.ucl.ac.uk/st'
         b'aff/M.Pontil/courses/fast-training.pdf">\nSMO Method to train SVM'
         b's\n</A>\n</TD>\n<TD>Available</TD>\n<TD>&nbsp</TD>\n</TR>\n\n<TR><T'
         b'D>\n<A href="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/optim'
         b'al.pdf">\nLearning multiple parameters with SVMs\n</A>\n</TD>\n<TD>A'
         b'vailable</TD>\n<TD>&nbsp</TD>\n</TR>\n\n<!--<TR><TD>\n<A href="ht'
         b'tp://www.cs.ucl.ac.uk/staff/M.Pontil/courses/leave-one-out.pdf">'
         b'\nLeave-one-out error\n</A>\n</TD>\n<TD>Available</TD>\n<TD>&nbsp'
         b'</TD>\n</TR>-->\n\n<TR><TD>\n<A href="http://www.cs.ucl.ac.uk/staff/'
         b'M.Pontil/courses/proceedingA.pdf">\nReduced sets methods\n</A>\n</T'
         b'D>\n<TD>Available</TD>\n<TD>&nbsp</TD>\n</TR>\n\n<TR><TD>\n<A href'
         b'="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/kernel-PCA.pdf"'
         b'>\nKernel PCA paper\n</A>\n</TD>\n<TD>Tao</TD>\n<TD>Feb 4</TD>\n</'
         b'TR>\n\n<TR><TD>\n<A href="http://www.cs.ucl.ac.uk/staff/M.Pontil/co'
         b'urses/SVMgeometry.pdf">\nGeometry of SVM classifiers\n</A>\n</TD>\n<'
         b'TD>Available</TD>\n<TD>&nbsp</TD>\n</TR>\n</TD></TR>\n</TBODY></TABL'
         b'E></P>\n\n  <P></P>\n  <H2><A name=briefsyllabus></A>Syllabus</H2>T'
         b'he tentative schedule of the \n  course is listed below. Follow t'
         b'he link for each class to find a detailed \n  description, sugges'
         b'ted readings, and lecture slides. \n  <P><BR>\n  <TABLE border=1>\n'
         b'    <TBODY>\n    <TR>\n      <TH>Date</TH>\n      <TH>Title</TH></T'
         b'R>\n    <TR>\n      <TD>Tuesday, January 11</TD>\n      <TD><A \n   '
         b'     href="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/ATML-1.pdf'
         b'">Kernels in Machine Learning</A>\n\n<p>\n-- Ridge Regression <br>\n'
         b'-- Feature maps <br>\n-- Positive definite kernels <br>\n-- kernel'
         b' construction <br>\n-- kernel on Euclidean spaces <br>\n\n</TD></TR'
         b'>\n    <TR>\n      <TD>Friday, January 12</TD>\n      <TD><A \n     '
         b'   href="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/ATML-2.pdf">'
         b'Kernel-Based Learning Algorithms</A>\n<p>\n\n-- Simple operation in'
         b' feature space <br>\n-- Kernel PCA <br>\n-- Novelty detection <br>'
         b'\n-- Optimal separating hyperplane <br>\n-- Soft margin separation'
         b' <br>\n-- Support vector machines <br>\n-- Extensions <br>\n\n</TD><'
         b'/TR>\n    <TR>\n      <TD>Friday, January 21</TD>\n      <TD><A \n  '
         b'      href="http://www.cs.ucl.ac.uk/staff/M.Pontil/courses/ATML-3.pd'
         b'f">Reproducing Kernel Hilbert Spaces</A>\n\n<p>\n-- Hilbert spaces '
         b'<br>\n-- Reproducing kernel Hilbert space <br>\n-- Mercer theorem '
         b'<br>\n-- Regularization, representer theorem <br>\n</TD></TR>\n<TR>'
         b'\n      <TD>Friday, February 4</TD>\n      <TD><A\n        href="ht'
         b'tp://www.cs.ucl.ac.uk/staff/M.Pontil/courses/ATML-pI.pdf">Individual'
         b' Presentations I </A>\n<p>\n-- TBA\n</TD></TR>\n<TR>\n      <TD>F'
         b'riday, February 11</TD>\n      <TD><A \n        href="http://www.c'
         b's.ucl.ac.uk/staff/M.Pontil/courses/ATML-pII.pdf">Individual Presenta'
         b'tions II </A>\n<p>\n-- TBA\n</TD></TR>\n</TBODY></TABLE></P>\n\n  '
         b'<H2><A name=readings></A><B>Reading List</B></H2>\n  <UL>\nMain Bo'
         b'ok:\n<p>\n    <LI>J. Shawe-Taylor and N. Cristianini. <B>Kernel Me'
         b'thods for Pattern Analysis. \n    Cambridge University Press</B>,'
         b' 2004. \n<p>\n\nOther suggested references:\n    <LI>N. Cristianini '
         b'and J. Shawe-Taylor</B>.An Introduction to Support Vector Machines. '
         b'Cambridge University Press, 2000. \n<LI>T. Hastie, R. Tibshirani,'
         b' and J. Friedman.\n<B>The Elements of Statistical Learning: Data '
         b'Mining,\nInference, and Prediction</B>. Springer Series in Statis'
         b'tics, 2002.\n<LI>B.Sch\\"olkopf and A.J. Smola.<B>Learning with Ke'
         b'rnels</B>. \n    MIT Press, 2002. \n <LI>V.N. Vapnik.<B>Statistica'
         b'l Learning Theory</B>. \n    Wiley, New York, 1998. \n<LI>G. Wahba'
         b'. <B>Splines Models for Observational Data</B>. Series in Applied Ma'
         b'thematics, Vol. 59, SIAM, Philadelphia, 1990.\n</LI>\n</UL>\n\n\n'
         b'     \n<HR>\n</BODY></HTML>\n',
 'links': [3437, 3471],
 'pid': 3527,
 'url': 'http://www0.cs.ucl.ac.uk/staff/M.Pontil/courses/index-ATML05.htm'}