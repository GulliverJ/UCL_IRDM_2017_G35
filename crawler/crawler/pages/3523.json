{'html': b'<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN"><html><head><title>GI0'
         b'1/4C55: Supervised Learning, Fall 2005</title></head>\n\n<body bgc'
         b'olor="#ffffff" text="#000000">\n    \n<h1>  \n<center>GI01/4C55: Su'
         b'pervised Learning, Fall 2005\n </center>\n  </h1>\n    \n<hr>  \n'
         b'<blockquote>     \n  <table>\n  <tbody>\n       <tr>\n         <td a'
         b'lign="right"><b>Class Times:</b></td>\n         <td>Mondays, 14:0'
         b'0--17:00</td>\n       </tr>\n       <tr>\n         <td align="right'
         b'"><b>Location:</b></td>\n         <td>Gordon Square (24), Room 10'
         b'5</td>\n       </tr>\n  <tr>\n         <td align="right"><b>Instruc'
         b'tor:</b></td>\n  <td><a href="http://www.cs.ucl.ac.uk/staff/M.Pon'
         b'til/">Massimiliano Pontil\n         </td>\n  </tr>\n  <tr>\n<!--    '
         b'     <td align="right"><b>Office Hours:</b></td>\n         <td></'
         b'td>-->\n  </tr>\n  <tr>\n         <td align="right"><b>Email Contac'
         b't :</b></td>\n         <td><b><a href="mailto:gi01">gi01@cs.ucl.a'
         b'c.uk</a></b></td>\n  </tr>\n    </tbody>   \n  </table>\n      \n'
         b'  <ul>\n  <li><a href="#description">Course description</a></li>\n'
         b'  <li><a href="#requirements">Prerequisites</a></li>\n  <li><a hr'
         b'ef="#grading">Grading</a></li>\n  <li><a href="#psets">Problem se'
         b'ts</a></li>\n  <li><a href="#briefsyllabus">Syllabus</a></li>\n  <'
         b'li><a href="#readings">Reading list</a></li>\n     \n  </ul>\n     '
         b'  \n  <h2><a name="description"></a><b>Course description</b></h2'
         b'>\nThe course covers supervised approaches to machine learning. I'
         b't starts by reviewing fundamentals of statistical learning and proba'
         b'bilistic pattern recognition followed by an in-depth introduction to'
         b' various supervised learning algorithms such as Least Squares, Logis'
         b'tic Regression, Perceptron Algorithm, Backpropagation, Decision Tree'
         b's, Instance-based Learning, Support Vector Machines and Boosting'
         b'. \n    \n  <h2><a name="requirements"></a><b>Prerequisites</b></h'
         b'2>\nCalculus, basic probability, basic linear algebra. \n\n  <h2><a'
         b' name="grading"></a><b>Grading</b></h2>\nThe course has the follo'
         b'wing assessment components: 1) Written Examination (2.5 hours, 60%) '
         b', 2) Coursework Section (5 pieces, 40%). To pass this course, studen'
         b'ts must obtain at least 40% on the coursework component and an avera'
         b'ge of at least 50% when the coursework and exam components of a cour'
         b'se are weighted together.\n  <p>  </p>\n  <h2><a name="psets"></a>'
         b'<b>Problem sets</b></h2>\n  Problem set #1: <a href="SL-homework1'
         b'.pdf">PDF</a> (Due: Noon, October 21)<br>\n  Problem set #2: <a h'
         b'ref="SL-homework2.pdf">PDF</a> (Due: Noon, November 4)<br>\n  Pro'
         b'blem set #3: <a href="SL-homework3.pdf">PDF</a> (Due: Noon, November'
         b' 23)<br>\n  Problem set #4: <a href="SL-homework4.pdf">PDF</a> (D'
         b'ue: Noon, December 5)<br>\n  Problem set #5: <a href="SL-homework'
         b'5.pdf">PDF</a> (Due: Noon, December 16)<br>\n    <p>  </p>\n  <h2>'
         b'<a name="briefsyllabus"></a>Syllabus</h2>\nThe schedule of the co'
         b'urse is listed below. Follow the link for each class \nto find \n<'
         b'!--a detailed description, suggested readings and -->\nlecture sl'
         b'ides. \n  <p>  <br>\n     \n  <table border="1">\n  <tbody>\n    '
         b'   <tr>\n         <th>Date</th>\n         <th>Title</th>\n       </'
         b'tr>\n  <tr>\n         <td>Monday, October 3</td>\n         <td><a h'
         b'ref="SL-1.pdf">Introduction to Supervised Learning</a></td>\n    '
         b'   </tr>\n  <tr>\n         <td>Monday, October 10</td>\n         <t'
         b'd><a href="SL-2.pdf">Discriminative and Generative Models</a></t'
         b'd>\n       </tr>\n  <tr>\n         <td>Monday, October 17</td>\n    '
         b'     <td><a href="SL-3.pdf">Optimization and Learning Algorithms</a>'
         b'</td>\n       </tr>\n  <tr>\n         <td>Monday, October 24</td>\n '
         b'        <td><a href="SL-4.pdf">Regularization, Kernels</a></td>\n'
         b'       </tr>\n  <tr>\n         <td>Monday, October 31</td>\n       '
         b'  <td><a href="SL-5.pdf">Elements of Learning Theory</a></td>\n  '
         b'     </tr>\n  <tr>\n         <td>Monday, November 7</td>\n         '
         b'<td>No lectures (reading week)</a></td>\n       </tr>\n  <tr>\n    '
         b'     <td>Monday, November 14</td>\n         <td><a href="SL-6.pdf'
         b'">Support Vector Machines / Bayesian Interpretations</a></td>\n  '
         b'     </tr>\n  <tr>\n         <td>Monday, November 21</td>\n        '
         b' <td><a href="SL-7.pdf">Trees-based Algorithms</a></td>\n       <'
         b'/tr>\n  <tr>\n         <td>Monday, November 28</td>\n         <td><'
         b'a href="SL-8.pdf">Boosting</a></td>\n       </tr>\n  <tr>\n        '
         b' <td>Monday, December 5</td>\n         <td><a href="SL-9.pdf">Neu'
         b'ral Networks</a></td>\n       </tr>\n  <tr>\n         <td>Monday, D'
         b'ecember 12</td>\n         <td><!--<a href="SL-10.pdf">-->Multi-ta'
         b'sk Learning</a></td>\n       </tr>\n    </tbody>   \n  </table>\n   '
         b'</p>\n   \n  <H2><A name=readings></A><B>Reading list</B></H2>\n  <'
         b'UL>\nMain reference:\n<p>\n<li>\nT. Hastie, R. Tibshirani and J. Fri'
         b'edman. <b>The Elements of Statistical Learning: Data Mining, \nIn'
         b'ference, and Prediction. </b>Springer, 2002. \n</li>\n<p>\n        '
         b'                                                                    '
         b'                             \nOther suggested references:\n<li>\nC'
         b'.M. Bishop. <b>Neural Networks for Pattern Recognition.</b> Oxford U'
         b'niv. Press, 1997.\n</li>\n<li>\nR.O. Duda, P.E. Hart and D.G. Stork'
         b'. <b>Pattern Classification.</b> Wiley, 2nd edition, 2004.\n</li>'
         b'\n<li>\nD.J.C. MacKay. <b>Information Theory, Pattern Recognition '
         b'and Neural Networks.</b> Cambridge Press, 2003 </li>\n<li>\nT. Mit'
         b'chell. <b>Machine Learning.</b> McGraw Hill, 1997\n <LI>J. Shawe-'
         b'Taylor and N. Cristianini. <B>Kernel Methods for Pattern Analysi'
         b's.\n    Cambridge University Press</B>, 2004.\n</li>\n <LI>B.Scholk'
         b'opf and A.J. Smola. <B>Learning with Kernels</B>.\n    MIT Press,'
         b' 2002.\n</li>\n <LI>V.N. Vapnik. <B>Statistical Learning Theory</B'
         b'>.\n    Wiley, New York, 1998.\n</LI>\n</UL>\n\n    \n</ul>\n</bloc'
         b'kquote>\n<hr>\n \n</body></html>\n',
 'links': [3437, 3523],
 'pid': 3523,
 'url': 'http://www0.cs.ucl.ac.uk/staff/M.Pontil/courses/index-SL05.htm'}